{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Learning(SL):\n",
    "    SL algorithims are trained using lebeled\n",
    "    \n",
    "    Labeled means Input where desired output is known\n",
    "    \n",
    "    Examples of lebeled : i. legitmate vs spam in email ii. Positive vs Negative movie review\n",
    "    \n",
    "    network receives set of inputs along with correct outputs and alogirhim learns by comparing its actual output\n",
    "    with correct outptus to find the errors\n",
    "    \n",
    "    it then modified the model accordingly \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "supervised learning is commonly used in applications where historical data predicts likely future events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learing Process:\n",
    "                                      -                                \n",
    "    data acquisition -> data cleaning ->Model Training and building -> model Tetsing->Model Deployment\n",
    "    ->test Data--------------------->model Tetsing->Model Deployement\n",
    "     ->model Tetsing->Model Training and Building\n",
    "                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Acquisition:\n",
    "i. get your data directly from customer,data from database,sensor data (physical data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning: \n",
    "    i. clean  data using pandas dataframe\n",
    "    \n",
    "  The split data into training and test  using Python ML module. might 30% will be test data and 70% for train\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's split the dataset into 3 sets : i. training ii. validation iii. test\n",
    "i. training -> feed to model\n",
    "ii. validation -> data used to validate the model.. based on validation, model can be modfied or re-architect to perform better\n",
    "iii. test data can be used to final performance of model where no need to modify the model as modification of model done during validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Performace - Classification Error Metrics:\n",
    "\n",
    "i. after machine learning process complete then use the performace metrics to evaluate how model did\n",
    "\n",
    "ii. key Classfication metrics are a.Accuracy b.Recall c.Precision d.F1-Score\n",
    "\n",
    "iii.Any Classification task your model can achieve 2 results : a. correct in its prediction b. incorrect in prediction  \n",
    "\n",
    "iv.Fortunately correct vs incorrect expands to situation where you have multiple classes\n",
    "\n",
    "v.for binary classification situation where we only have 2 avialable classes \n",
    "\n",
    "vi .in real world, not all incorrect and correct matches hold equal value\n",
    "\n",
    "vii.Real world,singel metric would not tell the complete story hence 4 metrics is been calculated\n",
    "\n",
    "viii. organize the predicted values compared to the real values in confusion matrix\n",
    "\n",
    "IX. Accuracy: Accuary in classfication problem = no. of corrected predictions/Total no. of predictions\n",
    "\n",
    "X. Accuary in classificaion problem is useful only when target classes are well balanced\n",
    "\n",
    "Xi. well balanced : acutally labels(cat image or dog image) in input dataset are equally represent (evenly distributed)\n",
    "\n",
    "xii. if target classes are un-balanced then accuracy is not a good metric to use\n",
    "\n",
    "xiii. un-balanced classes : example , we have input data (training data) which contains 99% dog image and 1% cat image to predict dog or cat. in this case input data is un-balanced .. hence your model predicted dog image will 90% accuracy\n",
    "\n",
    "Xiv : for the case of un-balanced , need to understand recall and Precision\n",
    "\n",
    "Xv: Recall : i. ablity of model to find all relevant cases within dataset ii. Recall= no. of true positive/(no. of true positive + no .of false negative)\n",
    "\n",
    "Xvi : precision : i. ability of clasification model to idenify only the relevent data points ii. Precesion : number of true positive/(no. of true positive+no. of false positive)\n",
    "\n",
    "Xvii : difference between precision and recall : recall expresses the ability to find all the relevant instances in dataset but precesion expresses the proprtion of the data model says was relevent actually were relevent\n",
    "\n",
    "Xviii. F1Score: combination of recall and precesion. F1Score=2*((recall * precesion)/(recall + precesion) .this is called harmonic mean of precesion and recall\n",
    "\n",
    "XIX: Confustion Matrix: view all correctly classified vs in-correctly classified . There are 2 catagory of prediction i. Prediction postive ii. prediction negative . i. Prediction positive  has 2 sub catagories a. True positive b. False Positive .ii.prediction negative has 2 sub catagories i. False negative ii. True negative\n",
    "\n",
    "XX: Exaplantion : True condtion has two types i. Condition postive (image is dog) ii. Condition negative(image is not a dog) then predection result may be in 4 ways 1. True positive ( actuall its  dog image and model predict its dog image) 2. False negative (Actuall its dog image but model predict its not a dog image ) (its error from model called Type 2 error) 3.False postive(actually its not a dog image but model predict its dog image(its error from model called type 1 error) 4.True negative (its actually not a dog image and model predict its not a dog image)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Performace - Regression Error Metrics:\n",
    "\n",
    "i. Regression is task where  model attempts to predicts contineous values ( unlike categorical values which is classification problem)\n",
    "\n",
    "ii. Most common evaluation metrics for regression: a.Mean absolute Error b. Mean Squared Error c.Root Mean Square Error\n",
    "\n",
    "iii. Mean absolute error: Yi -> True value Yi^ -> predicted value. Mean absolute error=(|y1-y1^|+|y1-y1^|+...+yn-1-yn-1^|+|yn-yn^|)/n\n",
    "\n",
    "iv.Mean absolute error would not punish large error.it means when actual value is more far from predicted regression line.. in that case mean absolute error did not work\n",
    "\n",
    "v. Mean Square Error=(square of(y1-y1^)|+square of(y1-y1^)+...+square of(yn-1-yn-1^)+square of (yn-yn^))/n\n",
    "\n",
    "vi.Root Mean Square Error=squar root of ((square of(y1-y1^)|+square of(y1-y1^)+...+square of(yn-1-yn-1^)+square of (yn-yn^))/n)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
